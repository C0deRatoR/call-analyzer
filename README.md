# ğŸ§ CallÂ Analyzer

Transcribeâ€¯&â€¯analyze recorded c## ğŸš€ Quick Start

### Option 1: Web Interface (Recommended)

```bash
# 1. Clone the repository
git clone https://github.com/C0deRatoR/call-analyzer.git
cd call-analyzer

# 2. Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Create .env file with your Gemini API key
echo "API_KEY=your_gemini_api_key_here" > .env

# 5. Start the web application
cd src
python app.py

# 6. Open your browser and go to: http://127.0.0.1:5000
```

### Option 2: Command Line Interface

```bash
# Process an audio file directly
python src/main.py samples/university_admission.wav
```

### ğŸ”‘ Getting Your Gemini API Key

1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Sign in with your Google account  
3. Create a new API key
4. Copy the key and paste it in your `.env` file

### ğŸ“ Supported Audio Formats

- WAV, MP3, M4A, FLAC
- Any format supported by FFmpeg

---

## ğŸ“– How It Works

1. **ğŸ¤ Upload Audio**: Use the web interface to upload your audio file
2. **ğŸ“ Transcription**: Whisper processes the audio locally and generates a transcript
3. **ğŸ¤– AI Analysis**: Gemini analyzes the transcript to provide:
   - **Summary**: Key topics and main points discussed
   - **Sentiment**: Emotional tone and mood analysis  
   - **Suggestions**: Alternative counselor responses for better guidance
4. **ğŸ“Š Results**: View all analysis results in a clean web interface

---

## ğŸ› ï¸ Development

### Project Structure

- `src/app.py` - Flask web application with file upload and processing endpoints
- `src/main.py` - CLI interface and main processing logic
- `src/whisper_module.py` - Audio transcription using OpenAI Whisper
- `src/gemini_module.py` - AI analysis using Google Gemini API
- `web/index.html` - Clean web interface for uploads and results

### Running in Development Mode

```bash
# Start with debug mode enabled
cd src
python app.py
```

---

## ğŸ”§ Configuration

All configuration is handled through environment variables in the `.env` file:

```env
# Required: Your Google Gemini API key
API_KEY=your_gemini_api_key_here
```

---

## ğŸ“‹ Requirements

- Python 3.12+
- Virtual environment (recommended)
- Google Gemini API key
- FFmpeg (for audio processing)

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.OpenAIÂ Whisper** and **GoogleÂ Gemini** (or any LLM).  
Ideal for support, sales, or research teams that need fast insights from audio.

&nbsp;

| ğŸ›  Techâ€¯Stack | ğŸ”– Status |
|--------------|-----------|
| PythonÂ 3.9+  | ![GitHub last commit](https://img.shields.io/github/last-commit/C0deRatoR/call-analyzer?style=flat-square) |
| WhisperÂ CPPÂ /Â PyTorch | ![Issues](https://img.shields.io/github/issues/C0deRatoR/call-analyzer?style=flat-square) |
| GoogleÂ GeminiÂ API | ![License](https://img.shields.io/github/license/C0deRatoR/call-analyzer?style=flat-square) |

---

## âœ¨ Features

- **Accurate transcription** with Whisper (local or API)
- **Summaries & keyword extraction** powered by an LLM (Gemini by default)
- Optional **textâ€‘toâ€‘speech** synthesis for audio demos
- Simple **web interface** (`index.html`) & CLI entry point
- Modular architecture â†’ dropâ€‘in replacement of models or frontâ€‘ends

---

## ğŸ—‚ Project Layout

```
call-analyzer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py              # Flask web application
â”‚   â”œâ”€â”€ main.py             # CLI entry point
â”‚   â”œâ”€â”€ whisper_module.py   # Audio transcription
â”‚   â”œâ”€â”€ gemini_module.py    # AI analysis (summary, sentiment, suggestions)
â”‚   â””â”€â”€ generate_audio.py   # Sample audio generator
â”œâ”€â”€ web/
â”‚   â””â”€â”€ index.html          # Web interface
â”œâ”€â”€ samples/
â”‚   â””â”€â”€ university_admission.wav  # Sample audio file
â”œâ”€â”€ venv/                   # Virtual environment
â”œâ”€â”€ uploads/                # Uploaded files storage
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env                   # API keys (create this!)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸš€ QuickÂ Start

```bash
# 1. Clone
git clone https://github.com/C0deRatoR/call-analyzer.git
cd call-analyzer

# 2. Install dependencies (preferably in a venv)
pip install -r requirements.txt

# 3. Transcribe & analyze an audio file
python src/main.py samples/AudioRec.mp3
